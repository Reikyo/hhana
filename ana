#!/usr/bin/env python

"""
This is the main driver script for the analysis
"""

from mva.cmd import get_parser

args = get_parser().parse_args()
year = args.year

# stdlib imports
import os, sys
import shutil

# rootpy imports
from rootpy.tree import Cut
from rootpy.io import root_open
from rootpy.stats import histfactory
from rootpy.plotting import Hist2D, Hist
from rootpy.utils.silence import silence_sout_serr

# root imports
import ROOT

# numpy imports
import numpy as np

# local imports
from mva.stats import hypotests
from mva.plotting import draw_scatter, draw_samples_array, draw_2d_hist, draw_channel_array
from mva.samples import Higgs
from mva.utils import make_multipage_pdf, braindump
from mva.systematics import (get_systematics, iter_systematics,
    parse_systematics, systematic_name)
from mva.categories import CATEGORIES
from mva.massregions import MassRegions
from mva.variables import VARIABLES, WEIGHTS
from mva.analysis import Analysis
from mva.lumi import get_lumi_uncert
from mva import log, variables, samples

CONST_PARAMS = [
    'Lumi',
    'mu_XS8_ggH',
    'mu_XS7_ggH',
    'mu_XS8_VBF',
    'mu_XS7_VBF',
    'mu_XS8_WH',
    'mu_XS7_WH',
    'mu_XS8_ZH',
    'mu_XS7_ZH',
    'mu_BR_tautau',
]

SYSTEMATICS = get_systematics(year)
lumi_rel_error = get_lumi_uncert(year)
args.systematics_components = parse_systematics(args.systematics_components)
figures = {}
category_scores = {}

mass_regions = MassRegions(
    low=args.low_mass_cut,
    high=args.high_mass_cut,
    high_sideband_in_control=args.high_sideband_in_control,
    mass_window_signal_region=args.mass_window_signal_region)

control_region = mass_regions.control_region
signal_region = mass_regions.signal_region
#signal_region = control_region

train_region = mass_regions.train_region

all_channels = {}
categories = CATEGORIES[args.categories]
category_names = args.category_names
target_region = args.target_region

analysis = Analysis(
    year=args.year,
    systematics=args.systematics,
    use_embedding=args.embedding,
    target_region=args.target_region,
    qcd_shape_region=args.qcd_shape_region,
    fit_param=args.fit_param,
    random_mu=args.random_mu,
    mu=args.mu,
    partition_key='EventNumber', # 'MET_phi_original * 100', or None
    suffix=args.suffix,
    transform=not args.raw_scores,
    mpl=args.mpl)

output_suffix = analysis.get_suffix()


if 'yields' in args.actions:
    """
    Create a table of sample yields in each category and control region
    """
    import math

    class ufloat(object):
        def __init__(self, value, uncert):
            self.value = value
            self.uncert = uncert

        def __str__(self):
            return repr(self)

        def __repr__(self):
            pos = int(math.floor(math.log10(abs(self.uncert))))
            pos = abs(pos) if pos < 0 else 1
            fmt = '${0:.'+str(pos)+'f}\pm {1:.'+str(pos)+'f}$'
            return fmt.format(self.value, self.uncert)

    for category in analysis.iter_categories(
            args.categories, args.controls, names=args.category_names):
        samples = []
        for sample in analysis.signals:
            events = sample.events(category, target_region)
            samples.append((sample._label, events))
        total_model = Hist(1, -100, 100)
        for sample in analysis.backgrounds:
            events = sample.events(category, target_region)
            total_model += events
            samples.append((sample._label, events))
        data_events = analysis.data.events(category, target_region)
        samples.append(('Total Background', total_model))
        samples.append(('Data', data_events))
        for name, events in samples:
            log.info("{0} & {1}".format(
                name, ufloat(
                events.GetBinContent(1),
                events.GetBinError(1))))


if 'ntup' in args.actions:
    # create an ntuple containing trees for each sample with classifier scores
    # and event weights
    
    from root_numpy import array2tree
    from numpy.lib import recfunctions

    with root_open('hhntup.root', 'recreate') as out:
        samples = analysis.backgrounds[:]
        for mass in Higgs.MASS_POINTS:
            signals = analysis.get_signals(mass)
            samples.extend(signals)

        for category in analysis.iter_categories(
                args.categories, args.controls, names=args.category_names):

            if category.analysis_control:
                continue

            clf = analysis.get_clf(category, load=True)
            
            for sample in samples:
                scores_dict = sample.scores(
                    clf, category, target_region,
                    systematics=args.systematics,
                    systematics_components=sample.WORKSPACE_SYSTEMATICS)
                for systematic, (scores, weights) in scores_dict.items():
                    rec = sample.merged_records(
                        category, target_region, systematic=systematic)
                    output_name = '{0}_category_{1}_systematic_{2}'.format(
                        sample.name,
                        category.name,
                        systematic_name(systematic))
                    rec = recfunctions.rec_append_fields(rec,
                        names='score',
                        data=scores,
                        dtypes='f4')
                    tree = array2tree(rec, name=output_name)
                    tree.Write()


if 'ntuptruth' in args.actions:
    # create an ntuple containing trees for each sample with classifier scores
    # and event weights
    
    from root_numpy import array2tree

    with root_open('hhntup_theory_uncert.root', 'recreate') as out:

        signals = [
            Higgs(year, mass=125, mode='VBF', systematics=False),
            Higgs(year, mass=125, mode='gg', systematics=False),
            Higgs(year, mass=125, mode='gg',
                  sample_pattern='McAtNloJimmy_AUET2CT10_ggH{0:d}_tautau',
                  systematics=False),
            Higgs(year, mass=125, mode='gg',
                  sample_pattern='PowhegJimmy_AUET2CT10_ggH{0:d}_tautauInclusive',
                  systematics=False)
        ]

        for category in analysis.iter_categories(
                args.categories, args.controls, names=args.category_names):

            if category.analysis_control:
                continue
            
            clf = analysis.get_clf(category, load=True)
            
            for sample in signals:
                tree = sample.trees(
                    category, target_region)[0]
                scores_dict = sample.scores(
                    clf, category, target_region,
                    systematics=False)

                scores, weights = scores_dict['NOMINAL']
                
                new_fields = np.c_[scores, weights]
                rec = np.core.records.fromarrays(
                    new_fields.transpose(),
                    names='score, weight',
                    formats='f4, f4')
                    
                output_name = '{0}_category_{1}'.format(
                    sample.samples[0],
                    category.name).replace('.', '_')
                
                tree.SetWeight(1.)

                # add branches to existing tree
                array2tree(rec, tree=tree)

                out.cd()
                outtree = tree.CloneTree(-1, 'fast')
                outtree.SetWeight(1.)
                outtree.Write(output_name)


for category in analysis.iter_categories(
    args.categories, args.controls, names=args.category_names):

    is_control = category.analysis_control

    if 'plot' in args.actions:
        figures[category.name] = {}
        cuts = Cut(args.plot_cut)

        if args.plot_expr is not None:
            VARS = {tuple(args.plot_expr.split(',')):
                    {'title': args.plot_name,
                     'range': (args.plot_min, args.plot_max),
                     'bins': args.plot_bins,
                     'filename': 'expr_' + args.plot_name.replace(' ', '_')}}
        else:
            VARS = VARIABLES

        figs = draw_channel_array(
            analysis,
            vars=VARS,
            mass=125,
            mode='combined',
            signal_scale=50,
            category=category,
            region=target_region,
            show_qq=False,
            plot_signal_significance=False,
            systematics=SYSTEMATICS if args.systematics else None,
            systematics_components=args.systematics_components,
            mpl=args.mpl,
            output_formats=args.output_formats,
            weighted=not args.no_weight,
            plots=args.plots,
            output_suffix=output_suffix,
            unblind=args.unblind or is_control,
            cuts=cuts)
        figures[category.name] = figs
    
    if 'weights' in args.actions:
        cuts = Cut(args.plot_cut)
        draw_samples_array(
            WEIGHTS,
            data=analysis.data,
            model=analysis.backgrounds,
            signal=[analysis.higgs_125],
            signal_scale=50,
            category=category,
            region=target_region,
            show_ratio=False,
            show_qq=False,
            plot_signal_significance=False,
            systematics=None,
            mpl=args.mpl,
            output_formats=args.output_formats,
            output_suffix=output_suffix,
            weighted=False,
            stacked_model=False,
            cuts=cuts)

    if 'train' in args.actions and not is_control:
        # all modes, all masses
        signals_train = [
            Higgs(
                year=year,
                mass=125,
                modes=category.train_signal_modes,
                systematics=args.systematics),
        ]

        clf = analysis.get_clf(category, load=False)
        
        clf.train(
            signals=signals_train,
            backgrounds=analysis.backgrounds,
            cuts=train_region,
            grid_search=args.grid_search,
            cv_nfold=args.nfold,
            use_cache=args.use_clf_cache)
    
    if 'money' in args.actions and not is_control:

        scores = analysis.get_scores(clf, category, target_region,
                mode='combined', mass_points=[125],
                systematics=args.systematics,
                unblind=True)

        from rootpy.plotting import Hist, Canvas, HistStack
        from mva.classify import histogram_scores
        from mva.stats.utils import significance
        from itertools import izip

        b = Hist(1000, scores.min_score, scores.max_score)
        s = b.Clone()
        for sample, bkg_scores in scores.bkg_scores:
            histogram_scores(b, bkg_scores, inplace=True)
        for sample, sig_scores in scores.all_sig_scores[125]:
            histogram_scores(s, sig_scores, inplace=True)

        # get min and max significance
        sig, _, _ = significance(s, b)
        min_sig, max_sig = sig.min(), sig.max()
        sig_money = Hist(10, min_sig, max_sig + 1E-5,
            drawstyle='hist',
            fillstyle='solid')
        bkg_money = sig_money.Clone()
        d_money = sig_money.Clone()

        for bin, _s in izip(s.bins(), sig):
            sig_money.Fill(_s, bin.value)
        for bin, _b in izip(b.bins(), sig):
            bkg_money.Fill(_b, bin.value)
        
        bkg_money.color = 'blue'
        sig_money.color = 'red'

        c = Canvas()
        c.SetLogy()
        stack = HistStack()
        stack.Add(bkg_money)
        stack.Add(sig_money)
        stack.Draw()
        stack.xaxis.title = 'S / #sqrt{S + B}'
        stack.yaxis.title = 'Events'
        stack.SetMinimum(10)
        stack.SetMaximum(1000)
        stack.Draw()
        stack.yaxis.SetRangeUser(10, 1000)
        stack.yaxis.SetLimits(10, 1000)
        c.SaveAs('money_{0}.png'.format(category.name))


    if '2d' in args.actions and not is_control:
        log.info("plotting 2d mass vs classifier output")
        draw_2d_hist(
            clf,
            category,
            target_region,
            analysis.backgrounds,
            signals=analysis.signals,
            data=analysis.data,
            cuts=signal_region,
            y='mass_mmc_tau1_tau2',
            output_suffix=output_suffix)

    if 'correlate' in args.actions:
        log.info("drawing correlation matrices")
        # TODO
        # create correlation matrices for signal, background
        # and background and data in a control region

    if 'scatter' in args.actions and not is_control:
        # show 2D plots of all input variables and with BDT output
        log.info("drawing scatter plots of input variables")
        draw_scatter(
            clf.all_fields,
            category,
            target_region,
            output_suffix,
            analysis.backgrounds,
            data=analysis.data,
            signals=analysis.signals,
            signal_scale=300.,
            classifier=clf if 'train' in args.actions else None,
            unblind=args.unblind)

    if 'evaluate' in args.actions and not is_control:
        # create BDT validation plots
        clf.evaluate(
            analysis,
            signal_region=signal_region,
            control_region=control_region,
            unblind=args.unblind,
            systematics=SYSTEMATICS if args.systematics else None,
            output_formats=args.output_formats,
            mpl=args.mpl)

        #category_scores[category.name] = (bkg_scores, sig_scores)


if 'workspace' in args.actions:

    if args.mass_points == 'all':
        args.mass_points = Higgs.MASS_POINTS
    else:
        args.mass_points = map(int, args.mass_points.split(','))

    workspace_suffix = output_suffix
    if args.workspace_suffix:
        workspace_suffix += '_' + args.workspace_suffix
    workspace_suffix = workspace_suffix.lower()
    
    # create control region Channels here
    control_analysis = Analysis(
        year=year,
        systematics=args.systematics,
        use_embedding=args.embedding,
        qcd_shape_region='SS',
        partition_key=analysis.partition_key,
        suffix=args.suffix,
        transform=not args.raw_scores,
        mpl=args.mpl)
    
    controls = []
    expr = ('tau1_numTrack_recounted', 'tau2_numTrack_recounted')
    # define the 2D boundaries and number of bins
    min_edge, max_edge = .5, 4.5
    bins = int(max_edge - min_edge)
    # define the histogram template
    hist_template = Hist2D(bins, min_edge, max_edge,
                           bins, min_edge, max_edge, type='D')

    for category in CATEGORIES['mva_workspace_controls']:
        parent_category = category.get_parent()

        # apply normalization
        control_analysis.normalize(parent_category, fit_param=args.fit_param)
        
        # clf = analysis.get_clf(parent_category, load=True)

        contr = control_analysis.get_channel(hist_template, expr,
            category=category,
            region='OS',
            #clf=clf,
            #cuts=signal_region,
            include_signal=False)
        controls.append(contr)
        # TODO check that number of SS events is consistent with nOS
    
    # yup, adding Channels using rootpy's HistFactory pythonizations
    controls = [sum(controls)]

    for category in categories:
        
        # apply normalization
        analysis.normalize(category, fit_param=args.fit_param)

        clf = analysis.get_clf(category, load=True)

        if args.optimize_limits:
            # Determine the number of bins that yields the best limit at 125
            channels = hypotests.optimized_channels(
                clf, category, target_region,
                analysis.backgrounds,
                data=analysis.data, 
                cuts=signal_region,
                mass_points=args.mass_points,
                mu=analysis.mu,
                systematics=args.systematics,
                lumi_rel_error=lumi_rel_error,
                algo='EvenBinningByLimit',
                #algo='UnevenBinningBySignificance',
                #unblind=args.unblind
                )
        else:
            # construct a "channel" for each mass point
            channels = hypotests.channels(
                clf, category, target_region,
                analysis.backgrounds,
                data=analysis.data, 
                cuts=signal_region,
                bins=category.limitbins,
                binning=category.limitbinning,
                mass_points=args.mass_points,
                mu=analysis.mu,
                systematics=args.systematics,
                unblind=args.unblind)

        for mass, channel in channels.items():
            if mass not in all_channels:
                all_channels[mass] = {}
            all_channels[mass][category.name] = channel
    
    workspace_output_dir = 'workspaces/hh%s' % workspace_suffix
    if os.path.exists(workspace_output_dir):
        shutil.rmtree(workspace_output_dir)
    os.mkdir(workspace_output_dir)

    for mass, category_channel in all_channels.items():

        channels = []
        
        # make workspace for each category, including the control region in each
        for category, channel in category_channel.items():
            name = "hh_category_%s_%d" % (category, mass)
            # make workspace
            workspace, measurement = histfactory.make_workspace(
                name, [channel] + controls,
                POI='SigXsecOverSM',
                lumi=1.0,
                lumi_rel_error=lumi_rel_error,
                const_params=CONST_PARAMS,
                silence=True)

            with root_open(os.path.join(workspace_output_dir,
                '{0}.root'.format(name)), 'recreate') as workspace_file:
                
                workspace.Write()
                
                # mu=1 for Asimov data
                #measurement.SetParamValue('SigXsecOverSM', 1)

                histfactory.write_measurement(measurement,
                    root_file=workspace_file,
                    xml_path=os.path.join(workspace_output_dir, name),
                    silence=True)

                if 'limits' in args.actions:
                    # get limit
                    limit_hist = hypotests.get_limit_workspace(workspace)
                    limit_hist.Write()

            channels.append(channel)

        # make combined workspace
        name = "hh_combination_%d" % mass
        workspace, measurement = histfactory.make_workspace(
            name, channels + controls,
            POI='SigXsecOverSM',
            lumi=1.0,
            lumi_rel_error=lumi_rel_error,
            const_params=CONST_PARAMS,
            silence=True)

        with root_open(os.path.join(workspace_output_dir,
            '{0}.root'.format(name)), 'recreate') as workspace_file:
            
            workspace.Write()
            
            # mu=1 for Asimov data
            #measurement.SetParamValue('SigXsecOverSM', 1)

            histfactory.write_measurement(measurement,
                root_file=workspace_file,
                xml_path=os.path.join(workspace_output_dir, name),
                silence=True)

            if 'limits' in args.actions:
                # determine limit with combined model
                limit_hist = hypotests.get_limit_workspace(workspace)
                limit_hist.Write()
