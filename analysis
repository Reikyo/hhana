#!/usr/bin/env python

import rootpy
rootpy.log.basic_config_colorized()

import logging
logging.captureWarnings(True) 

from rootpy.extern import argparse
from categories import CATEGORIES, CONTROLS, DEFAULT_LOW_MASS, DEFAULT_HIGH_MASS
from variables import VARIABLES


class formatter_class(argparse.ArgumentDefaultsHelpFormatter,
                      argparse.RawTextHelpFormatter):
    pass


parser = argparse.ArgumentParser(formatter_class=formatter_class)
"""
General Options
"""
parser.add_argument('--actions', nargs='*',
        choices=['validate', 'plot', 'train'],
        default=[],
        help='only perform these actions')
parser.add_argument('--no-systematics', action='store_false',
        dest='systematics',
        help="turn off systematics",
        default=True)
parser.add_argument('--categories', nargs='*', default=CATEGORIES.keys(),
        help='which categories to draw plot or train in')
"""
parser.add_argument('--controls', nargs='*', default=CONTROLS.keys(),
        help='which controls to draw plots in')
parser.add_argument('--only-controls', action='store_true', default=False,
        help='only draw control plots. no category plots.')
parser.add_argument('--enable-controls', action='store_true', default=False,
        help='plot in controls')
"""
parser.add_argument('--unblind', action='store_true', default=False,
        help='plot the data in the signal region of the classifier output')
parser.add_argument('--embedding', action='store_true', default=False,
        help='use embedding instead of ALPGEN')
parser.add_argument('--year', type=int, default=2011, choices=(2011, 2012),
        help='the year')

"""
Mass Regions Options
"""
parser.add_argument('--low-mass-cut', type=int,
        default=DEFAULT_LOW_MASS,
        help='the low mass window cut. '
        'Norms of Z and QCD are fit below this and '
        'the signal region of the classifier output is above this')
parser.add_argument('--high-mass-cut', type=int,
        default=DEFAULT_HIGH_MASS,
        help='the high mass window cut. '
        'Norms of Z and QCD are fit above this and '
        'the signal region of the classifier output is below this')
parser.add_argument('--no-sideband-in-control',
        dest='high_sideband_in_control',
        action='store_false',
        default=True,
        help='Exclude the high mass sideband in the mass control and include '
        'it in the signal region')

"""
Fitting Options
"""
parser.add_argument('--refit',
        action='store_false', dest='use_fit_cache',
        help="do not use cached background scale factors "
        "and instead recalculate them",
        default=True)
parser.add_argument('--fit-param', choices=('bdt', 'track', 'track1d'),
        default='track',
        help='parameters used to determine normalization of QCD and Z')
parser.add_argument('--draw-fit', action='store_true', default=False,
        help='draw the QCD/Z norm fit results')

"""
Training Options
"""
parser.add_argument('--retrain',
        action='store_false', dest='use_clf_cache',
        help="do not use cached classifier "
        "and instead train a new one",
        default=True)
parser.add_argument('--nfold', type=int, default=5,
        help='the number of folds in the cross-validation')
parser.add_argument('--clf-bins', dest='bins', type=int, default=10,
        help='the number of bins to use in the limit histograms and plots of '
        'the final classifier output')
parser.add_argument('--train-fraction', type=float, default=.5,
        help='the fraction of events used for training and excluded from the '
        'final limit histograms')
parser.add_argument('--train-categories', nargs='*', default=[],
        help='only train in these categories')
parser.add_argument('--quick-train', action='store_true', default=False,
        help='perform a very small grid search for testing purposes')
parser.add_argument('--grid-search', action='store_true', default=False,
        help='perform a grid-searched cross validation')
parser.add_argument('--forest-feature-ranking',
        action='store_true', default=False,
        help='Use a random forest to perform a feature ranking.')
parser.add_argument('--correlations', action='store_true', default=False,
        help='draw correlation plots')
parser.add_argument('--ranking', action='store_true', default=False,
        help='only show the variable rankings')

"""
Plotting Options
"""
parser.add_argument('--plots', nargs='*',
        help='only draw these plots. see the keys in variables.py')
parser.add_argument('--plot-cut', default=None, nargs='?',
        help='extra cut to be applied on the plots, but excluded from the '
        'QCD/Z normaliation and training and classifier output')
parser.add_argument('--plot-expr', default=None, nargs='?',
        help='expression to plot, instead of predefined ones in variables.py')
parser.add_argument('--plot-name', default=None, nargs='?',
        help='name of expr')
parser.add_argument('--plot-min', type=float, default=0, nargs='?',
        help='minimum of expr')
parser.add_argument('--plot-max', type=float, default=1, nargs='?',
        help='maximum of expr')
parser.add_argument('--plot-bins', type=int, default=20, nargs='?',
        help='number of bins to plot expr in')
parser.add_argument('--root', action='store_true', default=False,
        help='draw plots with ROOT. default is matplotlib')
parser.add_argument('--suffix', default=None, nargs='?',
        help='suffix to add to any output files or plots')
parser.add_argument('--output-formats', default=['png'], nargs='+',
        choices=('png', 'eps', 'pdf'),
        help='output formats')

args = parser.parse_args()
year = args.year

# stdlib imports
import pickle
from pprint import pprint
import os

# rootpy imports
from rootpy.plotting import Hist
from rootpy.io import open as ropen
from rootpy.extern.tabulartext import PrettyTable

# root imports
import ROOT
ROOT.gROOT.SetBatch(True)

# numpy imports
import numpy as np

# matplotlib imports
from matplotlib import pyplot as plt

# local imports
from logger import log
from utils import *
from samples import *
import samples
from background_estimation import qcd_ztautau_norm
from classify import *
from config import plots_dir
from utils import *
import variables
from systematics import SYSTEMATICS
from categories import MassRegions


LIMITS_DIR = os.getenv('HIGGSTAUTAU_LIMITS_DIR')
if not LIMITS_DIR:
    sys.exit('You did not source setup.sh!')
LIMITS_DIR = os.path.join(LIMITS_DIR, 'hadhad')

PLOTS_DIR = plots_dir(__file__)

if args.embedding:
    ztautau = Embedded_Ztautau(
            year=year,
            systematics=args.systematics)
else:
    ztautau = MC_Ztautau(
            year=year,
            systematics=args.systematics)
others = Others(
        year=year,
        systematics=args.systematics)
data = Data(
        year=year,
        markersize=1.2)

higgs_125 = Higgs(
        year=year,
        mass=125,
        systematics=args.systematics,
        scale=50,
        linecolor='red')

if 'train' in args.actions:

    # all modes, all masses
    signals_train = [
        Higgs(
            year=year,
            systematics=args.systematics),
    ]

figures = {}

output_suffix = '_%sfit' % args.fit_param
if args.embedding:
    output_suffix += '_embedding'
if args.suffix:
    output_suffix += '_%s' % args.suffix
output_suffix += '_%d' % (year % 1E3)

mass_regions = MassRegions(
        low=args.low_mass_cut,
        high=args.high_mass_cut,
        high_sideband_in_control=args.high_sideband_in_control)

control_region = mass_regions.control_region
signal_region = mass_regions.signal_region
train_region = mass_regions.train_region

for category, cat_info in sorted(CATEGORIES.items(), key=lambda item: item[0]):

    if category not in args.categories:
        continue

    log.info("")
    log.info("=" * 40)
    log.info("%s category" % category)
    log.info("=" * 40)
    log.info("Cuts: %s" % cat_info['cuts'])
    
    # QCD shape region SS or !OS
    qcd_shape_region = cat_info['qcd_shape_region']
    target_region = cat_info['target_region']
    
    figures[category] = {}

    qcd = QCD(data=data, mc=[others, ztautau],
          shape_region=qcd_shape_region)
    
    qcd.scale = 1.
    ztautau.scale = 1.

    # determine normalization of QCD and Ztautau
    # in each category separately
    qcd_ztautau_norm(
        year=year,
        ztautau=ztautau,
        others=others,
        qcd=qcd,
        data=data,
        category=category,
        target_region=target_region,
        mass_regions=mass_regions,
        bins=cat_info['fitbins'],
        draw=args.draw_fit,
        use_cache=args.use_fit_cache,
        param=args.fit_param,
        systematics=SYSTEMATICS if args.systematics else None,
        root=args.root)

    if 'plot' in args.actions:
        cuts = Cut(args.plot_cut)

        if args.plot_expr is not None:
            VARS = {tuple(args.plot_expr.split(',')):
                    {'title': args.plot_name,
                     'range': (args.plot_min, args.plot_max),
                     'bins': args.plot_bins,
                     'cats': ['GGF'],
                     'filename': 'expr_' + args.plot_name.replace(' ', '_')}}
        else:
            VARS = VARIABLES

        for expr, var_info in VARS.items():

            if category in args.categories and category.upper() not in var_info['cats']:
                continue
            elif args.plots and expr not in args.plots:
                continue

            log.info("")
            log.info("plotting %s in %s category" % (expr, category))
            log.info(cat_info['cuts'] & cuts)

            bins = var_info['bins']
            min, max = var_info['range']

            if 'scale' in var_info:
                expr = "%s * %f" % (expr, var_info['scale'])

            other_hist = others.draw(
                    expr,
                    category, target_region,
                    bins, min, max,
                    cuts=cuts)

            qcd_hist = qcd.draw(
                    expr,
                    category, target_region,
                    bins, min, max,
                    cuts=cuts)

            ztautau_hist = ztautau.draw(
                    expr,
                    category, target_region,
                    bins, min, max,
                    cuts=cuts)

            bkg_hists = [qcd_hist, other_hist, ztautau_hist]

            data_hist = data.draw(
                    expr,
                    category, target_region,
                    bins, min, max,
                    cuts=cuts)

            signal_hist = higgs_125.draw(
                    expr,
                    category, target_region,
                    bins, min, max,
                    cuts=cuts)

            log.info("Data events: %d" % sum(data_hist))
            log.info("Model events: %f" % sum(sum(bkg_hists)))
            for hist in bkg_hists:
                log.info("{0} {1}".format(hist.GetTitle(), sum(hist)))
            log.info("Data / Model: %f" % (sum(data_hist) /
                sum(sum(bkg_hists))))

            output_name = var_info['filename'] + output_suffix
            if cuts:
                output_name += '_' + cuts.safe()

            fig = draw(
                    data=data_hist,
                    model=bkg_hists,
                    signal=signal_hist,
                    name=var_info['root'] if args.root else var_info['title'],
                    output_name=output_name,
                    category_name=cat_info['name'],
                    category=category,
                    units=var_info.get('units', None),
                    range=var_info['range'],
                    show_ratio=True,
                    show_qq=False,
                    plot_signal_significance=False,
                    dir=PLOTS_DIR,
                    systematics=SYSTEMATICS if args.systematics else None,
                    root=args.root,
                    output_formats=args.output_formats)
            figures[category][expr] = fig

    if 'train' in args.actions:

        backgrounds = [
            qcd,
            others,
            ztautau,
        ]

        # define training and test samples
        branches = cat_info['features']
        
        """
        if args.correlations:
                    branches = branches + ['mass_mmc_tau1_tau2']

                # split into testing and training samples
                sample_train, sample_test,\
                sample_weight_train, sample_weight_test,\
                labels_train, labels_test = make_classification(
                    signals_train, backgrounds,
                    category=category,
                    region=target_region,
                    branches=branches,
                    train_fraction=args.train_fraction,
                    max_sig_train=None,
                    max_bkg_train=None,
                    max_sig_test=None,
                    max_bkg_test=None,
                    norm_sig_to_bkg_train=True,
                    norm_sig_to_bkg_test=False,
                    same_size_train=True,
                    same_size_test=False,
                    remove_negative_train_weights=True,
                    standardize=False,
                    cuts=train_region)

                if args.correlations:
                    # draw a linear correlation matrix
                    samples.correlations(
                        signal=sample_test[labels_test==1],
                        signal_weight=sample_weight_test[labels_test==1],
                        background=sample_test[labels_test==0],
                        background_weight=sample_weight_test[labels_test==0],
                        branches=branches,
                        category=category,
                        output_suffix=output_suffix)
                    continue
        """

        clf = ClassificationProblem(
                signals=signals_train,
                backgrounds=backgrounds,
                fields=branches,
                category=category,
                region=target_region,
                cuts=None,
                output_suffix=output_suffix)

        clf.train(
                grid_search=args.grid_search,
                quick=args.quick_train,
                cv_nfold=args.nfold,
                use_cache=args.use_clf_cache)

        # show the background model and 125 GeV signal over the full mass range
        log.info("plotting classifier output over all mass...")

        # determine min and max scores
        min_score = 1.
        max_score = 0.

        # background model scores
        bkg_scores = []
        for bkg in backgrounds:
            scores_dict = bkg.scores(clf,
                    region=target_region)

            for sys_term, (scores, weights) in scores_dict.items():
                assert len(scores) == len(weights)
                if len(scores) == 0:
                    continue
                _min = np.min(scores)
                _max = np.max(scores)
                if _min < min_score:
                    min_score = _min
                if _max > max_score:
                    max_score = _max

            bkg_scores.append((bkg, scores_dict))

        sig_scores = []
        # signal scores
        for mode in Higgs.MODES:
            sig = Higgs(year=year, mode=mode, mass=125,
                    systematics=args.systematics)
            scores_dict = sig.scores(clf,
                    region=target_region)

            for sys_term, (scores, weights) in scores_dict.items():
                assert len(scores) == len(weights)
                if len(scores) == 0:
                    continue
                _min = np.min(scores)
                _max = np.max(scores)
                if _min < min_score:
                    min_score = _min
                if _max > max_score:
                    max_score = _max

            sig_scores.append((sig, scores_dict))

        log.info("minimum score: %f" % min_score)
        log.info("maximum score: %f" % max_score)

        # prevent bin threshold effects
        min_score -= 0.00001
        max_score += 0.00001

        # add a bin above max score and below min score for extra beauty
        score_width = max_score - min_score
        bin_width = score_width / args.bins
        min_score -= bin_width
        max_score += bin_width

        # compare data and the model in a mass control region
        plot_clf(
            background_scores=bkg_scores,
            category=category,
            category_name=cat_info['name'],
            plot_label='full mass range',
            signal_scores=sig_scores,
            signal_scale=50,
            draw_data=True,
            name='full_range' + output_suffix,
            bins=args.bins + 2,
            min_score=min_score,
            max_score=max_score,
            systematics=SYSTEMATICS if args.systematics else None)

        # show the background model and data in the control region
        log.info("plotting classifier output in control region...")
        log.info(control_region)
        # data scores
        data_scores, _ = data.scores(clf,
                region=target_region,
                cuts=control_region)

        # determine min and max scores
        min_score = 1.
        max_score = 0.
        _min = data_scores.min()
        _max = data_scores.max()
        if _min < min_score:
            min_score = _min
        if _max > max_score:
            max_score = _max

        # background model scores
        bkg_scores = []
        for bkg in backgrounds:
            scores_dict = bkg.scores(clf,
                    region=target_region,
                    cuts=control_region)

            for sys_term, (scores, weights) in scores_dict.items():
                assert len(scores) == len(weights)
                if len(scores) == 0:
                    continue
                _min = np.min(scores)
                _max = np.max(scores)
                if _min < min_score:
                    min_score = _min
                if _max > max_score:
                    max_score = _max

            bkg_scores.append((bkg, scores_dict))

        log.info("minimum score: %f" % min_score)
        log.info("maximum score: %f" % max_score)

        # prevent bin threshold effects
        min_score -= 0.00001
        max_score += 0.00001

        # add a bin above max score and below min score for extra beauty
        score_width = max_score - min_score
        bin_width = score_width / args.bins
        min_score -= bin_width
        max_score += bin_width

        # compare data and the model in a low mass control region
        plot_clf(
            background_scores=bkg_scores,
            category=category,
            category_name=cat_info['name'],
            plot_label='mass control region',
            signal_scores=None,
            data_scores=(data, data_scores),
            draw_data=True,
            name='control' + output_suffix,
            bins=args.bins + 2,
            min_score=min_score,
            max_score=max_score,
            systematics=SYSTEMATICS if args.systematics else None)

        # plot the signal region and save histograms for limit-setting
        log.info("Plotting classifier output in signal region...")
        log.info(signal_region)

        if args.unblind:
            # data scores
            data_scores, _ = data.scores(clf,
                    region=target_region,
                    cuts=signal_region)

        # background model scores
        bkg_scores = []
        for bkg in backgrounds:
            scores_dict = bkg.scores(clf,
                    region=target_region,
                    cuts=signal_region)

            for sys_term, (scores, weights) in scores_dict.items():
                assert len(scores) == len(weights)

            bkg_scores.append((bkg, scores_dict))

        root_filename = '%s%s.root' % (category, output_suffix)
        f = ropen(os.path.join(LIMITS_DIR, root_filename), 'recreate')

        for mass in Higgs.MASS_POINTS:
            log.info("%d GeV mass hypothesis" % mass)
            # create separate signal. background and data histograms for each
            # mass hypothesis since the binning is optimized for each mass
            # individually.
            # The binning is determined by first locating the BDT cut value at
            # which the signal significance is maximized (S / sqrt(B)).
            # Everything above that cut is put in one bin. Everything below that
            # cut is put into N variable width bins such that the background is
            # flat.
            min_score_signal = 1.
            max_score_signal = 0.
            sig_scores = []
            # signal scores
            for mode in Higgs.MODES:
                sig = Higgs(year=year, mode=mode, mass=mass,
                        systematics=args.systematics)
                scores_dict = sig.scores(clf,
                        region=target_region,
                        cuts=signal_region)

                for sys_term, (scores, weights) in scores_dict.items():
                    assert len(scores) == len(weights)
                    if len(scores) == 0:
                        continue
                    _min = np.min(scores)
                    _max = np.max(scores)
                    if _min < min_score_signal:
                        min_score_signal = _min
                    if _max > max_score_signal:
                        max_score_signal = _max

                sig_scores.append((sig, scores_dict))

            log.info("minimum signal score: %f" % min_score_signal)
            log.info("maximum signal score: %f" % max_score_signal)

            # prevent bin threshold effects
            min_score_signal -= 0.00001
            max_score_signal += 0.00001

            # add a bin above max score and below min score for extra beauty
            score_width_signal = max_score_signal - min_score_signal
            bin_width_signal = score_width_signal / args.bins

            plot_clf(
                background_scores=bkg_scores,
                signal_scores=sig_scores,
                category=category,
                category_name=cat_info['name'],
                plot_label='mass signal region',
                signal_scale=50,
                name='%d_ROI%s' % (mass, output_suffix),
                bins=args.bins + 2,
                min_score=min_score_signal - bin_width_signal,
                max_score=max_score_signal + bin_width_signal,
                systematics=SYSTEMATICS if args.systematics else None)

            if cat_info['limitbinning'] == 'variable':
                log.info("variable-width bins")
                # determine location that maximizes signal significance
                bkg_hist = Hist(100, min_score_signal, max_score_signal)
                sig_hist = bkg_hist.Clone()
                # fill background
                for bkg_sample, scores_dict in bkg_scores:
                    score, w = scores_dict['NOMINAL']
                    bkg_hist.fill_array(score, w)
                # fill signal
                for sig_sample, scores_dict in sig_scores:
                    score, w = scores_dict['NOMINAL']
                    sig_hist.fill_array(score, w)

                # determine maximum significance
                sig, max_sig, max_cut = significance(sig_hist, bkg_hist, min_bkg=1)
                log.info("maximum signal significance of %f at score > %f" % (
                        max_sig, max_cut))

                # determine N bins below max_cut or N+1 bins over the whole signal
                # score range such that the background is flat
                # this will require a binary search for each bin boundary since the
                # events are weighted.
                """
                flat_bins = search_flat_bins(
                        bkg_scores, min_score_signal, max_score_signal,
                        int(sum(bkg_hist) / 20))
                """
                flat_bins = search_flat_bins(
                        bkg_scores, min_score_signal, max_cut, 5)
                # one bin above max_cut
                flat_bins.append(max_score_signal)

                plot_clf(
                    background_scores=bkg_scores,
                    signal_scores=sig_scores,
                    category=category,
                    category_name=cat_info['name'],
                    plot_label='mass signal region',
                    signal_scale=50,
                    name='%d_ROI_flat%s' % (mass, output_suffix),
                    bins=flat_bins,
                    plot_signal_significance=False,
                    signal_on_top=True,
                    systematics=SYSTEMATICS if args.systematics else None)

                hist_template = Hist(flat_bins)
            else:
                log.info("constant-width bins")
                hist_template = Hist(cat_info['limitbins'],
                        min_score_signal, max_score_signal)

            data_hist = hist_template.Clone(name=data.name + '_%s' % mass)
            if args.unblind:
                data_hist.fill_array(data_scores)
            else:
                # write out the sum of the background model as "data"
                for bkg_sample, scores_dict in bkg_scores:
                    score, w = scores_dict['NOMINAL']
                    data_hist.fill_array(score, w)
            f.cd()
            data_hist.Write()
            write_score_hists(f, mass, bkg_scores, hist_template, no_neg_bins=True)
            write_score_hists(f, mass, sig_scores, hist_template, no_neg_bins=True)

        f.close()

# save all variable plots in one large multipage pdf
if figures and set(args.categories) == set(CATEGORIES.keys()) and not args.plots:
    # only create multipage pdf of all plots if we created all plots
    from matplotlib.backends.backend_pdf import PdfPages
    import datetime
    now = datetime.datetime.today()
    # put all plots in a multipage pdf
    for category, exprs in figures.items():
        pdf = PdfPages(os.path.join(
            PLOTS_DIR, 'variables_%s%s.pdf' % (category, output_suffix)))
        for expr, fig in sorted(exprs.items(), key=lambda x: x[0]):
            pdf.savefig(fig)
        d = pdf.infodict()
        # set pdf metadata
        d['Title'] = 'Features'
        d['Author'] = 'Noel Dawe'
        d['Subject'] = 'Higgs tautau hh features'
        d['Keywords'] = 'higgs tau'
        d['CreationDate'] = now
        d['ModDate'] = now
        pdf.close()
