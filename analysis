#!/usr/bin/env python

"""
This is the main driver script for the analysis
"""

from mva.cmd import get_parser

args = get_parser().parse_args()
year = args.year

# stdlib imports
import os, sys
import shutil

# rootpy imports
from rootpy.tree import Cut
from rootpy.io import root_open as ropen
from rootpy.fit import histfactory
from rootpy.plotting import Hist2D

# root imports
import ROOT

# numpy imports
import numpy as np

# local imports
from mva.stats import hypotests
from mva.plotting import draw_scatter, draw_samples_array, draw_2d_hist
from mva.samples import Higgs
from mva.utils import make_multipage_pdf, braindump
from mva.classify import ClassificationProblem
from mva.systematics import get_systematics, iter_systematics
from mva.categories import CATEGORIES
from mva.massregions import MassRegions
from mva.variables import VARIABLES, WEIGHTS
from mva.analysis import Analysis
from mva.lumi import get_lumi_uncert
from mva import log, variables, samples

CONST_PARAMS = [
    'Lumi',
    'mu_XS8_ggH',
    'mu_XS7_ggH',
    'mu_XS8_VBF',
    'mu_XS7_VBF',
    'mu_XS8_WH',
    'mu_XS7_WH',
    'mu_XS8_ZH',
    'mu_XS7_ZH',
    'mu_BR_tautau',
]

partition_key = 'MET_phi_original * 100'
#partition_key = None

SYSTEMATICS = get_systematics(year)
lumi_rel_error = get_lumi_uncert(year)
figures = {}
category_scores = {}

mass_regions = MassRegions(
    low=args.low_mass_cut,
    high=args.high_mass_cut,
    high_sideband_in_control=args.high_sideband_in_control,
    mass_window_signal_region=args.mass_window_signal_region)

control_region = mass_regions.control_region
signal_region = mass_regions.signal_region
train_region = mass_regions.train_region

all_channels = {}
categories = CATEGORIES[args.categories]
category_names = args.category_names
target_region = args.target_region

analysis = Analysis(
    year=year,
    systematics=args.systematics,
    use_embedding=args.embedding,
    target_region=args.target_region,
    qcd_shape_region=args.qcd_shape_region,
    fit_param=args.fit_param,
    root=args.root)

output_suffix = analysis.get_suffix(args.fit_param, args.suffix)
clf_output_suffix = output_suffix
if not args.systematics:
    output_suffix += '_statsonly'

if args.transform_scores:
    ClassificationProblem.TRANSFORM = True

if args.mass_points == 'all':
    args.mass_points = Higgs.MASS_POINTS
else:
    args.mass_points = map(int, args.mass_points.split(','))


if 'yields' in args.actions:
    """
    Create a table of sample yields in each category and control region
    """
    for category in analysis.iter_categories(
            args.categories, args.controls, names=args.category_names):
        model_events = 0.
        log.info("Backgrounds:")
        bkg = []
        for sample in analysis.backgrounds:
            events = sample.events(category, target_region)
            bkg.append((sample._label, events))
            log.info("%s: %.4f (unweighted: %d)" % (
                sample.name, events,
                sample.events(category, target_region, raw=True)))
            model_events += events
        log.info("Signals:")
        sig = []
        for sample in analysis.signals:
            events = sample.events(category, target_region)
            sig.append((sample._label, events))
            log.info("%s: %.4f (unweighted: %d)" % (sample.mode,
                events,
                sample.events(category, target_region, raw=True)))
        if args.unblind:
            data_events = analysis.data.events(category, target_region)
            log.info("Data: %d" % data_events)
            log.info("Data / Model: %f" % (data_events / model_events))
        for name, events in bkg + sig:
            print "{0} & {1:.1f}".format(name, events)


for category in analysis.iter_categories(
    args.categories, args.controls, names=args.category_names):

    is_control = category.analysis_control

    if 'plot' in args.actions:
        figures[category.name] = {}
        cuts = Cut(args.plot_cut)

        if args.plot_expr is not None:
            VARS = {tuple(args.plot_expr.split(',')):
                    {'title': args.plot_name,
                     'range': (args.plot_min, args.plot_max),
                     'bins': args.plot_bins,
                     'filename': 'expr_' + args.plot_name.replace(' ', '_')}}
        else:
            VARS = VARIABLES

        figs = draw_samples_array(
            vars=VARS,
            data=analysis.data,
            model=analysis.backgrounds,
            signal=[analysis.higgs_125],
            signal_scale=50,
            category=category,
            region=target_region,
            show_ratio=True,
            show_qq=False,
            plot_signal_significance=False,
            systematics=SYSTEMATICS if args.systematics else None,
            root=args.root,
            output_formats=args.output_formats,
            weighted=not args.no_weight,
            plots=args.plots,
            output_suffix=output_suffix,
            unblind=args.unblind or is_control,
            cuts=cuts)
        figures[category.name] = figs
    
    if 'weights' in args.actions:
        cuts = Cut(args.plot_cut)
        draw_samples_array(
            WEIGHTS,
            data=analysis.data,
            model=analysis.backgrounds,
            signal=[analysis.higgs_125],
            signal_scale=50,
            category=category,
            region=target_region,
            show_ratio=False,
            show_qq=False,
            plot_signal_significance=False,
            systematics=None,
            root=args.root,
            output_formats=args.output_formats,
            output_suffix=output_suffix,
            weighted=False,
            stacked_model=False,
            cuts=cuts)

    if 'train' in args.actions and not is_control:
        # all modes, all masses
        signals_train = [
            Higgs(
                year=year,
                mass=125,
                modes=category.train_signal_modes,
                systematics=args.systematics),
        ]

        clf = ClassificationProblem(
            fields=category.features,
            category=category,
            region=target_region,
            clf_output_suffix=clf_output_suffix,
            output_suffix=output_suffix,
            partition_key=partition_key)
        
        clf.train(
            signals=signals_train,
            backgrounds=analysis.backgrounds,
            cuts=train_region,
            grid_search=args.grid_search,
            quick=args.quick_train,
            cv_nfold=args.nfold,
            use_cache=args.use_clf_cache)

    if '2d' in args.actions and not is_control:
        log.info("plotting 2d mass vs classifier output")
        draw_2d_hist(
            clf,
            category,
            target_region,
            analysis.backgrounds,
            signals=analysis.signals,
            data=analysis.data,
            cuts=signal_region,
            y='mass_mmc_tau1_tau2',
            output_suffix=output_suffix)

    if 'correlate' in args.actions:
        log.info("drawing correlation matrices")
        # TODO
        # create correlation matrices for signal, background
        # and background and data in a control region

    if 'scatter' in args.actions and not is_control:
        # show 2D plots of all input variables and with BDT output
        log.info("drawing scatter plots of input variables")
        draw_scatter(
            clf.all_fields,
            category,
            target_region,
            output_suffix,
            analysis.backgrounds,
            data=analysis.data,
            signals=analysis.signals,
            signal_scale=300.,
            classifier=clf if 'train' in args.actions else None,
            unblind=args.unblind)

    if 'evaluate' in args.actions and not is_control:
        # create BDT validation plots
        clf.evaluate(
            analysis,
            signal_region=signal_region,
            control_region=control_region,
            unblind=args.unblind,
            systematics=SYSTEMATICS if args.systematics else None,
            limitbins=category.limitbins,
            limitbinning=category.limitbinning,
            quick=args.quick_eval,
            output_formats=args.output_formats,
            root=args.root)

        #category_scores[category.name] = (bkg_scores, sig_scores)


if 'workspace' in args.actions:

    workspace_suffix = output_suffix
    if args.workspace_suffix:
        workspace_suffix += '_' + args.workspace_suffix
    
    # create control region Channels here
    control_analysis = Analysis(
        year=year,
        systematics=args.systematics,
        use_embedding=args.embedding,
        qcd_shape_region='SS',
        root=args.root)
    
    controls = []
    expr = ('tau1_numTrack_recounted', 'tau2_numTrack_recounted')
    # define the 2D boundaries and number of bins
    min_edge, max_edge = .5, 4.5
    bins = int(max_edge - min_edge)
    # define the histogram template
    hist_template = Hist2D(bins, min_edge, max_edge,
                           bins, min_edge, max_edge, type='D')

    for category in CATEGORIES['mva_workspace_controls']:
        parent_category = category.get_parent()

        # apply normalization
        control_analysis.normalize(parent_category, fit_param=args.fit_param)

        clf = ClassificationProblem(
            fields=parent_category.features,
            category=parent_category,
            region='OS',
            clf_output_suffix=clf_output_suffix,
            output_suffix=output_suffix,
            partition_key=partition_key)

        if not clf.load():
            sys.exit("train BDTs before requesting workspaces")

        contr = control_analysis.get_channel(hist_template, expr,
            category=category,
            region='OS',
            clf=clf,
            include_signal=False)
        controls.append(contr)
        # TODO check that number of SS events is consistent with nOS
    
    # yup, adding Channels using rootpy's HistFactory pythonizations
    controls = [sum(controls)]

    for category in categories:
        
        # apply normalization
        analysis.normalize(category, fit_param=args.fit_param)

        clf = ClassificationProblem(
            fields=category.features,
            category=category,
            region=target_region,
            clf_output_suffix=clf_output_suffix,
            output_suffix=output_suffix,
            partition_key=partition_key)
        if not clf.load():
            sys.exit("train BDTs before requesting workspaces")

        if args.optimize_limits:
            # Determine the number of bins that yields the best limit at 125
            channels = hypotests.optimized_channels(
                clf, category, target_region,
                analysis.backgrounds,
                data=analysis.data, 
                cuts=signal_region,
                mass_points=args.mass_points,
                systematics=args.systematics,
                lumi_rel_error=lumi_rel_error,
                #algo='EvenBinningByLimit')
                algo='UnevenBinningBySignificance',
                unblind=args.unblind)
        else:
            # construct a "channel" for each mass point
            channels = hypotests.channels(
                clf, category, target_region,
                analysis.backgrounds,
                data=analysis.data, 
                cuts=signal_region,
                bins=category.limitbins,
                binning=category.limitbinning,
                mass_points=args.mass_points,
                systematics=args.systematics,
                unblind=args.unblind)

        for mass, channel in channels.items():
            if mass not in all_channels:
                all_channels[mass] = {}
            all_channels[mass][category.name] = channel

    """
    TODO: set const and nonconst params:

    Nils:

    <ParamSetting Const="True">mu_XS8_ggH mu_XS8_VBF mu_XS8_ZH mu_XS8_WH mu_BR_tautau </ParamSetting>
    <ParamSetting Const="True">Lumi </ParamSetting>
    <ParamSetting Const="False">alpha_ATLAS_ANA_EMB alpha_ATLAS_ANA_EMB_ISO alpha_ATLAS_BR_tautau alpha_ATLAS_EL_EFF_2012 alpha_ATLAS_EL_PSSTAT alpha_ATLAS_EL_RES alpha_ATLAS_EL_SCALER12 alpha_ATLAS_EL_ZEE alpha_ATLAS_JESB alpha_ATLAS_JESDET alpha_ATLAS_JESETAINTERMODEL alpha_ATLAS_JESETAINTERSTAT alpha_ATLAS_JESFLAV alpha_ATLAS_JESFLAVRESP alpha_ATLAS_JESMIX alpha_ATLAS_JESMODEL alpha_ATLAS_JESMU alpha_ATLAS_JESNPV alpha_ATLAS_JESPUPT alpha_ATLAS_JESPURHO alpha_ATLAS_JESSTAT alpha_ATLAS_LUMI_2012 alpha_ATLAS_MET_RESOSOFT alpha_ATLAS_MET_RESOSOFT_BKG_LH alpha_ATLAS_MET_SCALESOFT alpha_ATLAS_MET_SCALESOFT_BKG_LH alpha_ATLAS_MU_EFF_2012 alpha_ATLAS_MU_SCALE alpha_ATLAS_TAU_ID_2012 alpha_ATLAS_TAU_TES alpha_ATLAS_UE alpha_ATLAS_norm_SFEmb_2012 alpha_ATLAS_norm_SFEmb_2012_Ele alpha_ATLAS_norm_SFTopS_2012 alpha_ATLAS_norm_SFWJets_2012lh_1j__2012 alpha_ATLAS_norm_SFWJets_2012lh_boost__2012 alpha_ATLAS_norm_SFWJets_2012lh_e0j__2012 alpha_ATLAS_norm_SFWJets_2012lh_m0j__2012 alpha_ATLAS_norm_SFWJets_2012lh_vbf__2012 alpha_ATLAS_norm_SFZlllll2TauS_2012 alpha_ATLAS_norm_SF_QCD_2012 alpha_ATLAS_norm_SF_QCD_2012_Ele alpha_ATLAS_norm_SF_QCD_2012_Muon alpha_ATLAS_norm_SFdibosonS_2012 alpha_BTag_C alpha_BTag_b alpha_BTag_l alpha_EleID alpha_EleIso alpha_EleReco alpha_EleTrig alpha_MuonIDScaleFact alpha_MuonIso alpha_MuonTrig alpha_PU alpha_QCDscale_ggH alpha_QCDscale_ggH1in alpha_QCDscale_ggH2in alpha_QCDscale_qqH alpha_TauElFake alpha_TauTrig alpha_WPTDependence alpha_pdf_gg alpha_pdf_qqbar  </ParamSetting>
    """
    
    dump_dir = ROOT.gDirectory.func()

    with ropen('workspaces/limits%s.root' % workspace_suffix, 'recreate') as limits_file:
        braindump(limits_file, indir=dump_dir,
            func=lambda h: h.ClassName().startswith('TH') and
                           h.GetName().startswith('category'))

        xml_output_dir = 'workspaces/xml%s' % workspace_suffix
        if os.path.exists(xml_output_dir):
            shutil.rmtree(xml_output_dir)
        os.mkdir(xml_output_dir)
        for mass, category_channel in all_channels.items():
            channels = []
            # determine limits for each category separately
            for category, channel in category_channel.items():
                name = "category_%s_%d" % (category, mass)
                # make workspace
                workspace, measurement = histfactory.make_workspace(
                    name, [channel] + controls,
                    POI='SigXsecOverSM',
                    lumi=1.0,
                    lumi_rel_error=lumi_rel_error,
                    const_params=CONST_PARAMS)
                # mu=1 for Asimov data
                #measurement.SetParamValue('SigXsecOverSM', 1)
                workspace.Write()
                measurement.Write()
                measurement.PrintXML(xml_output_dir)
                if 'limits' in args.actions:
                    # get limit
                    limit_hist = hypotests.get_limit_workspace(workspace)
                    limit_hist.Write()
                channels.append(channel)
            # make combined workspace
            name = "combination_%d" % mass
            workspace, measurement = histfactory.make_workspace(
                name, channels + controls,
                POI='SigXsecOverSM',
                lumi=1.0,
                lumi_rel_error=lumi_rel_error,
                const_params=CONST_PARAMS)
            # mu=1 for Asimov data
            #measurement.SetParamValue('SigXsecOverSM', 1)
            workspace.Write()
            measurement.Write()
            measurement.PrintXML(xml_output_dir)
            if 'limits' in args.actions:
                # determine limit with combined model
                limit_hist = hypotests.get_limit_workspace(workspace)
                limit_hist.Write()
