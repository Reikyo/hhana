#!/usr/bin/env python

from mva.cmd import get_parser

args = get_parser().parse_args()
year = args.year

# stdlib imports
import pickle
from pprint import pprint
import os

# rootpy imports
from rootpy.plotting import Hist
from rootpy.io import open as ropen

# root imports
import ROOT

# numpy imports
import numpy as np

# local imports
from mva import log, variables, plots_dir, samples
from mva.plotting import *
from mva.samples import *
from mva.utils import make_multipage_pdf
from mva.norm import qcd_ztautau_norm
from mva.classify import *
from mva.systematics import SYSTEMATICS
from mva.categories import MassRegions, CATEGORIES
from mva.variables import VARIABLES


PLOTS_DIR = plots_dir(__file__)

if args.embedding:
    ztautau = Embedded_Ztautau(
            year=year,
            systematics=args.systematics)
else:
    ztautau = MC_Ztautau(
            year=year,
            systematics=args.systematics)
others = Others(
        year=year,
        systematics=args.systematics)
data = Data(
        year=year,
        markersize=1.2)

higgs_125 = Higgs(
        year=year,
        mass=125,
        systematics=args.systematics,
        scale=50,
        linecolor='red')

figures = {}

output_suffix = '_%sfit' % args.fit_param
if args.embedding:
    output_suffix += '_embedding'
if args.suffix:
    output_suffix += '_%s' % args.suffix
output_suffix += '_%d' % (year % 1E3)

mass_regions = MassRegions(
        low=args.low_mass_cut,
        high=args.high_mass_cut,
        high_sideband_in_control=args.high_sideband_in_control)

control_region = mass_regions.control_region
signal_region = mass_regions.signal_region
train_region = mass_regions.train_region

for category, cat_info in sorted(CATEGORIES.items(), key=lambda item: item[0]):

    if category not in args.categories:
        continue

    log.info("")
    log.info("=" * 40)
    log.info("%s category" % category)
    log.info("=" * 40)
    log.info("Cuts: %s" % cat_info['cuts'])
    
    # QCD shape region SS or !OS
    qcd_shape_region = cat_info['qcd_shape_region']
    target_region = cat_info['target_region']
    
    figures[category] = {}

    qcd = QCD(data=data, mc=[others, ztautau],
          shape_region=qcd_shape_region)
    
    qcd.scale = 1.
    ztautau.scale = 1.

    # determine normalization of QCD and Ztautau
    # in each category separately
    qcd_ztautau_norm(
        year=year,
        ztautau=ztautau,
        others=others,
        qcd=qcd,
        data=data,
        category=category,
        target_region=target_region,
        mass_regions=mass_regions,
        bins=cat_info['fitbins'],
        draw=args.draw_fit,
        use_cache=args.use_fit_cache,
        param=args.fit_param,
        systematics=SYSTEMATICS if args.systematics else None,
        root=args.root)

    if 'plot' in args.actions:
        cuts = Cut(args.plot_cut)

        if args.plot_expr is not None:
            VARS = {tuple(args.plot_expr.split(',')):
                    {'title': args.plot_name,
                     'range': (args.plot_min, args.plot_max),
                     'bins': args.plot_bins,
                     'cats': ['GGF'],
                     'filename': 'expr_' + args.plot_name.replace(' ', '_')}}
        else:
            VARS = VARIABLES

        for expr, var_info in VARS.items():

            if category in args.categories and category.upper() not in var_info['cats']:
                continue
            elif args.plots and expr not in args.plots:
                continue

            log.info("")
            log.info("plotting %s in %s category" % (expr, category))
            log.info(cat_info['cuts'] & cuts)

            bins = var_info['bins']
            min, max = var_info['range']

            if 'scale' in var_info:
                expr = "%s * %f" % (expr, var_info['scale'])

            other_hist = others.draw(
                    expr,
                    category, target_region,
                    bins, min, max,
                    cuts=cuts)

            qcd_hist = qcd.draw(
                    expr,
                    category, target_region,
                    bins, min, max,
                    cuts=cuts)

            ztautau_hist = ztautau.draw(
                    expr,
                    category, target_region,
                    bins, min, max,
                    cuts=cuts)

            bkg_hists = [qcd_hist, other_hist, ztautau_hist]

            data_hist = data.draw(
                    expr,
                    category, target_region,
                    bins, min, max,
                    cuts=cuts)

            signal_hist = higgs_125.draw(
                    expr,
                    category, target_region,
                    bins, min, max,
                    cuts=cuts)

            log.info("Data events: %d" % sum(data_hist))
            log.info("Model events: %f" % sum(sum(bkg_hists)))
            for hist in bkg_hists:
                log.info("{0} {1}".format(hist.GetTitle(), sum(hist)))
            log.info("Signal events: %f" % sum(signal_hist))
            log.info("Data / Model: %f" % (sum(data_hist) /
                sum(sum(bkg_hists))))

            output_name = var_info['filename'] + output_suffix
            if cuts:
                output_name += '_' + cuts.safe()

            fig = draw(
                    data=data_hist,
                    model=bkg_hists,
                    signal=signal_hist,
                    name=var_info['root'] if args.root else var_info['title'],
                    output_name=output_name,
                    category_name=cat_info['name'],
                    category=category,
                    units=var_info.get('units', None),
                    range=var_info['range'],
                    show_ratio=True,
                    show_qq=False,
                    plot_signal_significance=False,
                    dir=PLOTS_DIR,
                    systematics=SYSTEMATICS if args.systematics else None,
                    root=args.root,
                    output_formats=args.output_formats)
            figures[category][expr] = fig

    if 'train' in args.actions:

        backgrounds = [
            qcd,
            others,
            ztautau,
        ]
        
        # all modes, all masses
        signals_train = [
            Higgs(
                year=year,
                systematics=args.systematics),
        ]

        # define training and test samples
        branches = cat_info['features']
        
        clf = ClassificationProblem(
                signals=signals_train,
                backgrounds=backgrounds,
                fields=branches,
                category=category,
                region=target_region,
                cuts=None,
                output_suffix=output_suffix)

        clf.train(
                grid_search=args.grid_search,
                quick=args.quick_train,
                cv_nfold=args.nfold,
                use_cache=args.use_clf_cache)

        # show the background model and 125 GeV signal over the full mass range
        log.info("plotting classifier output over all mass...")

        # determine min and max scores
        min_score = 1.
        max_score = -1.

        # background model scores
        bkg_scores = []
        for bkg in backgrounds:
            scores_dict = bkg.scores(clf,
                    region=target_region)

            for sys_term, (scores, weights) in scores_dict.items():
                assert len(scores) == len(weights)
                if len(scores) == 0:
                    continue
                _min = np.min(scores)
                _max = np.max(scores)
                if _min < min_score:
                    min_score = _min
                if _max > max_score:
                    max_score = _max

            bkg_scores.append((bkg, scores_dict))

        sig_scores = []
        # signal scores
        for mode in Higgs.MODES:
            sig = Higgs(year=year, mode=mode, mass=125,
                    systematics=args.systematics)
            scores_dict = sig.scores(clf,
                    region=target_region)

            for sys_term, (scores, weights) in scores_dict.items():
                assert len(scores) == len(weights)
                if len(scores) == 0:
                    continue
                _min = np.min(scores)
                _max = np.max(scores)
                if _min < min_score:
                    min_score = _min
                if _max > max_score:
                    max_score = _max

            sig_scores.append((sig, scores_dict))

        log.info("minimum score: %f" % min_score)
        log.info("maximum score: %f" % max_score)

        # prevent bin threshold effects
        min_score -= 0.00001
        max_score += 0.00001

        # add a bin above max score and below min score for extra beauty
        score_width = max_score - min_score
        bin_width = score_width / args.bins
        min_score -= bin_width
        max_score += bin_width

        # compare data and the model in a mass control region
        plot_clf(
            background_scores=bkg_scores,
            category=category,
            category_name=cat_info['name'],
            plot_label='full mass range',
            signal_scores=sig_scores,
            signal_scale=50,
            draw_data=True,
            name='full_range' + output_suffix,
            bins=args.bins + 2,
            min_score=min_score,
            max_score=max_score,
            systematics=SYSTEMATICS if args.systematics else None)

        # show the background model and data in the control region
        log.info("plotting classifier output in control region...")
        log.info(control_region)
        # data scores
        data_scores, _ = data.scores(clf,
                region=target_region,
                cuts=control_region)

        # determine min and max scores
        min_score = 1.
        max_score = -1.
        _min = data_scores.min()
        _max = data_scores.max()
        if _min < min_score:
            min_score = _min
        if _max > max_score:
            max_score = _max

        # background model scores
        bkg_scores = []
        for bkg in backgrounds:
            scores_dict = bkg.scores(clf,
                    region=target_region,
                    cuts=control_region)

            for sys_term, (scores, weights) in scores_dict.items():
                assert len(scores) == len(weights)
                if len(scores) == 0:
                    continue
                _min = np.min(scores)
                _max = np.max(scores)
                if _min < min_score:
                    min_score = _min
                if _max > max_score:
                    max_score = _max

            bkg_scores.append((bkg, scores_dict))

        log.info("minimum score: %f" % min_score)
        log.info("maximum score: %f" % max_score)

        # prevent bin threshold effects
        min_score -= 0.00001
        max_score += 0.00001

        # add a bin above max score and below min score for extra beauty
        score_width = max_score - min_score
        bin_width = score_width / args.bins
        min_score -= bin_width
        max_score += bin_width

        # compare data and the model in a low mass control region
        plot_clf(
            background_scores=bkg_scores,
            category=category,
            category_name=cat_info['name'],
            plot_label='mass control region',
            signal_scores=None,
            data_scores=(data, data_scores),
            draw_data=True,
            name='control' + output_suffix,
            bins=args.bins + 2,
            min_score=min_score,
            max_score=max_score,
            systematics=SYSTEMATICS if args.systematics else None)

        # plot the signal region and save histograms for limit-setting
        log.info("Plotting classifier output in signal region...")
        log.info(signal_region)

        if args.unblind:
            # data scores
            data_scores, _ = data.scores(clf,
                    region=target_region,
                    cuts=signal_region)

        # background model scores
        bkg_scores = []
        for bkg in backgrounds:
            scores_dict = bkg.scores(clf,
                    region=target_region,
                    cuts=signal_region)

            for sys_term, (scores, weights) in scores_dict.items():
                assert len(scores) == len(weights)

            bkg_scores.append((bkg, scores_dict))

        root_filename = '%s%s.root' % (category, output_suffix)
        f = ropen(os.path.join(LIMITS_DIR, root_filename), 'recreate')

        for mass in Higgs.MASS_POINTS:
            log.info('=' * 20)
            log.info("%d GeV mass hypothesis" % mass)
            # create separate signal. background and data histograms for each
            # mass hypothesis since the binning is optimized for each mass
            # individually.
            # The binning is determined by first locating the BDT cut value at
            # which the signal significance is maximized (S / sqrt(B)).
            # Everything above that cut is put in one bin. Everything below that
            # cut is put into N variable width bins such that the background is
            # flat.
            min_score_signal = 1.
            max_score_signal = -1.
            sig_scores = []
            # signal scores
            for mode in Higgs.MODES:
                sig = Higgs(year=year, mode=mode, mass=mass,
                        systematics=args.systematics)
                scores_dict = sig.scores(clf,
                        region=target_region,
                        cuts=signal_region)

                for sys_term, (scores, weights) in scores_dict.items():
                    assert len(scores) == len(weights)
                    if len(scores) == 0:
                        continue
                    _min = np.min(scores)
                    _max = np.max(scores)
                    if _min < min_score_signal:
                        min_score_signal = _min
                    if _max > max_score_signal:
                        max_score_signal = _max

                sig_scores.append((sig, scores_dict))

            log.info("minimum signal score: %f" % min_score_signal)
            log.info("maximum signal score: %f" % max_score_signal)

            # prevent bin threshold effects
            min_score_signal -= 0.00001
            max_score_signal += 0.00001

            # add a bin above max score and below min score for extra beauty
            score_width_signal = max_score_signal - min_score_signal
            bin_width_signal = score_width_signal / args.bins

            plot_clf(
                background_scores=bkg_scores,
                signal_scores=sig_scores,
                category=category,
                category_name=cat_info['name'],
                plot_label='mass signal region',
                signal_scale=50,
                name='%d_ROI%s' % (mass, output_suffix),
                bins=args.bins + 2,
                min_score=min_score_signal - bin_width_signal,
                max_score=max_score_signal + bin_width_signal,
                systematics=SYSTEMATICS if args.systematics else None)

            if cat_info['limitbinning'] == 'flat':
                log.info("variable-width bins")
                # determine location that maximizes signal significance
                bkg_hist = Hist(100, min_score_signal, max_score_signal)
                sig_hist = bkg_hist.Clone()
                
                # fill background
                for bkg_sample, scores_dict in bkg_scores:
                    score, w = scores_dict['NOMINAL']
                    bkg_hist.fill_array(score, w)
                
                # fill signal
                for sig_sample, scores_dict in sig_scores:
                    score, w = scores_dict['NOMINAL']
                    sig_hist.fill_array(score, w)

                # determine maximum significance
                sig, max_sig, max_cut = significance(sig_hist, bkg_hist, min_bkg=1)
                log.info("maximum signal significance of %f at score > %f" % (
                        max_sig, max_cut))

                # determine N bins below max_cut or N+1 bins over the whole signal
                # score range such that the background is flat
                # this will require a binary search for each bin boundary since the
                # events are weighted.
                """
                flat_bins = search_flat_bins(
                        bkg_scores, min_score_signal, max_score_signal,
                        int(sum(bkg_hist) / 20))
                """
                flat_bins = search_flat_bins(
                        bkg_scores, min_score_signal, max_cut, 5)
                # one bin above max_cut
                flat_bins.append(max_score_signal)

                plot_clf(
                    background_scores=bkg_scores,
                    signal_scores=sig_scores,
                    category=category,
                    category_name=cat_info['name'],
                    plot_label='mass signal region',
                    signal_scale=50,
                    name='%d_ROI_flat%s' % (mass, output_suffix),
                    bins=flat_bins,
                    plot_signal_significance=False,
                    signal_on_top=True,
                    systematics=SYSTEMATICS if args.systematics else None)

                hist_template = Hist(flat_bins)

            elif cat_info['limitbinning'] == 'onebkg':
                # Define last bin such that it contains at least one background.
                # First histogram background with a very fine binning,
                # then sum from the right to the left up to a total of one
                # event. Use the left edge of that bin as the left edge of the
                # last bin in the final histogram template.
                # Important: also choose the bin edge such that all background
                # components each have at least zero events, since we have
                # samples with negative weights (SS subtraction in the QCD) and
                # MC@NLO samples.

                log.info("one background in last bin")
                total_bkg_hist = Hist(1000, min_score_signal, max_score_signal)
                sums = []
                
                # fill background
                for bkg_sample, scores_dict in bkg_scores:
                    score, w = scores_dict['NOMINAL']
                    bkg_hist = total_bkg_hist.Clone()
                    bkg_hist.fill_array(score, w)

                    # create array from histogram
                    bkg_array = np.array(bkg_hist)

                    # reverse cumsum
                    bkg_cumsum = bkg_array[::-1].cumsum()[::-1]

                    sums.append(bkg_cumsum)
               
                total_bkg_cumsum = np.add.reduce(sums)

                # determine last element with at least a value of 1.
                # and where each background has at least zero events
                # so that no sample may have negative events in this bin
                all_positive = np.logical_and.reduce([b >= 0. for b in sums])
                last_bin_all_positive = np.argmin(all_positive) - 1

                last_bin = int(min(np.where(bkg_cumsum >= 1.)[-1][-1],
                                   last_bin_all_positive))

                # get left bin edge corresponding to this bin
                bin_edge = bkg_hist.xedges(last_bin)

                # if this edge is greater than it would otherwise be if we used
                # constant-width binning over the whole range then just use the
                # original binning
                default_bins = list(np.linspace(
                        min_score_signal,
                        max_score_signal,
                        cat_info['limitbins'] + 1))

                if bin_edge > default_bins[-2]:
                    log.info("constant-width bins are OK")
                    one_bkg_bins = default_bins
                
                else:
                    log.info("adjusting last bin to contain >= one background")
                    log.info("original edge: %f  new edge: %f " %
                            (default_bins[-2],
                             bin_edge))
                    
                    # now define N-1 constant-width bins to the left of this edge
                    left_bins = np.linspace(
                            min_score_signal,
                            bin_edge,
                            cat_info['limitbins'])

                    one_bkg_bins = list(left_bins)
                    one_bkg_bins.append(max_score_signal)
                
                plot_clf(
                    background_scores=bkg_scores,
                    signal_scores=sig_scores,
                    category=category,
                    category_name=cat_info['name'],
                    plot_label='mass signal region',
                    signal_scale=50,
                    name='%d_ROI_onebkg%s' % (mass, output_suffix),
                    bins=one_bkg_bins,
                    plot_signal_significance=True,
                    systematics=SYSTEMATICS if args.systematics else None)

                hist_template = Hist(one_bkg_bins)

            else:
                log.info("constant-width bins")
                hist_template = Hist(cat_info['limitbins'],
                        min_score_signal, max_score_signal)

            data_hist = hist_template.Clone(name=data.name + '_%s' % mass)
            if args.unblind:
                data_hist.fill_array(data_scores)
            else:
                # write out the sum of the background model as "data"
                for bkg_sample, scores_dict in bkg_scores:
                    score, w = scores_dict['NOMINAL']
                    data_hist.fill_array(score, w)
            f.cd()
            data_hist.Write()
            write_score_hists(f, mass, bkg_scores, hist_template, no_neg_bins=True)
            write_score_hists(f, mass, sig_scores, hist_template, no_neg_bins=True)

        f.close()

# save all variable plots in one large multipage pdf
if figures and set(args.categories) == set(CATEGORIES.keys()) and not args.plots:
    # only create multipage pdf of all plots if we created all plots
    for category, exprs in figures.items():
        figs = sorted(exprs.items(), key=lambda x: x[0])
        make_multipage_pdf([fig[1] for fig in figs], name=category,
                dir=PLOTS_DIR)
