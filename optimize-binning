#!/usr/bin/env python
from rootpy.extern.argparse import ArgumentParser

parser = ArgumentParser()
parser.add_argument('--year', type=int, choices=(2011, 2012), default=2012)
args = parser.parse_args()

import os
from math import log
import pickle

from rootpy.plotting import Hist, Canvas
from rootpy.plotting import root2matplotlib as rplt
from rootpy.stats.histfactory import (
    Data, Sample, Channel, make_measurement, make_workspace)

from root_numpy import fill_hist
import numpy as np
import matplotlib.pyplot as plt

from mva import CONST_PARAMS, CACHE_DIR
from mva.categories import Category_VBF, Category_Boosted
from mva.analysis import Analysis

from statstools.fixups import fix_measurement
from statstools import get_significance_workspace


def search(f, a, b, tol=1.0e-9, **kwargs):
    """
    Golden section method for determining x that minimizes
    the user-supplied scalar function f(x).
    The minimum must be bracketed in (a,b).
    """
    nIter = int(-2.078087*log(tol/abs(b-a)))
    R = 0.618033989
    C = 1.0 - R
    # First telescoping
    x1 = R*a + C*b; x2 = C*a + R*b
    f1 = f(x1, **kwargs); f2 = f(x2, **kwargs)
    # Main loop
    for i in range(nIter):
        if f1 > f2:
            a = x1
            x1 = x2; f1 = f2
            x2 = C*a + R*b; f2 = f(x2, **kwargs)
        else:
            b = x2
            x2 = x1; f2 = f1
            x1 = R*a + C*b; f1 = f(x1, **kwargs)
    if f1 < f2:
        return x1, f1
    else:
        return x2, f2


def get_best_edge(scores, edges, pos=0, iter=200):
    left, right = edges[pos:pos+2]
    probe_edges = np.linspace(left, right, iter, endpoint=False)[1:]
    sigs = [get_sig(scores, edges, x, pos+1) for x in probe_edges]
    best_sig = np.max(sigs[10:])
    best_edge = probe_edges[np.argmax(sigs[10:]) + 10]
    return probe_edges, sigs, best_edge, best_sig


def get_workspace(scores, binning, fix=True):
    hist_template = Hist(binning)
    background = []
    for sample, scores_dict in scores.bkg_scores:
        background.append(sample.get_histfactory_sample(
            hist_template, None, category, 'OS', scores=scores_dict))
    # remove free norm factors

    signal = []
    for sample, scores_dict in scores.all_sig_scores[125]:
        signal.append(sample.get_histfactory_sample(
            hist_template, None, category, 'OS', scores=scores_dict))
    data_hist = sum([b.hist for b in background])
    data_hist.name = 'Data'
    data = Data('Data', data_hist)
    channel = Channel(category.name, signal + background, data)
    measurement = make_measurement('MVA', channel,
        POI='SigXsecOverSM',
        const_params=CONST_PARAMS)
    if fix:
        fix_measurement(measurement)
    return make_workspace(measurement, silence=False)


def get_sig(scores, binning, edge=None, pos=1):
    if edge is not None:
        binning = binning[:]
        binning.insert(pos, edge)
    ws = get_workspace(scores, binning)
    hist = get_significance_workspace(ws)
    sig = hist[2].value
    # handle nan
    return 0 if sig != sig else sig


def optimize_func(edge, scores, binning):
    return - get_sig(scores, binning, edge, 1)


systematics = False
transform = False

analysis = Analysis(args.year,
                    transform=transform,
                    systematics=systematics,
                    qcd_workspace_norm=False,
                    ztt_workspace_norm=False)

for category in (Category_VBF, Category_Boosted):
    analysis.normalize(category)
    clf = analysis.get_clf(category, load=True)
    scores = analysis.get_scores(
        clf, category, 'OS', mode='workspace',
        mass_points=[125], systematics=systematics)
    min_score, max_score = scores.min_score, scores.max_score

    # nominal scores for convenience
    b = np.concatenate([scores_dict['NOMINAL'][0] for _, scores_dict in scores.bkg_scores])
    bw = np.concatenate([scores_dict['NOMINAL'][1] for _, scores_dict in scores.bkg_scores])
    s = np.concatenate([scores_dict['NOMINAL'][0] for _, scores_dict in scores.all_sig_scores[125]])
    sw = np.concatenate([scores_dict['NOMINAL'][1] for _, scores_dict in scores.all_sig_scores[125]])
    min_score = min(np.min(s), np.min(b)) - 1E-8
    max_score = max(np.max(s), np.max(b)) + 1E-8
    s = (s, sw)
    b = (b, bw)
    
    fig = plt.figure()
    ax1 = fig.add_subplot(111)
    ax1.set_ylabel('Significance')
    ax1.set_xlabel('BDT Score')
    ax2 = ax1.twiny()
    ax2.set_xlabel('Number of Fixed-width Bins')
    ax3 = ax1.twinx()
    ax3.set_ylabel('Events')
    ax3.set_yscale('log')

    # plot the distributions
    b_hist = Hist(20, min_score, max_score, color='blue',
                  linewidth=3, linestyle='dashed')
    s_hist = b_hist.Clone(color='red')
    fill_hist(b_hist, *b)
    fill_hist(s_hist, *s)
    rplt.hist(b_hist, axes=ax3, label='Background')
    rplt.hist(s_hist, axes=ax3, label='Signal')

    # poor man's constant width binning
    nfixed_bins = range(1, 11)
    fixed_sigs = []
    for bins in nfixed_bins:
        fixed_sigs.append(get_sig(
            scores, np.linspace(min_score, max_score, bins + 1)))
    max_fixed_sig = np.max(fixed_sigs)
    max_fixed_nbins = nfixed_bins[np.argmax(fixed_sigs)]
    
    # show significance vs number of equal width bins
    ax2.plot(nfixed_bins, fixed_sigs, label='Fixed-width Bins', color='green', linestyle='-')

    # demonstrate smart binning
    from itertools import cycle
    lines = ["-","--","-.",":"]
    linecycler = cycle(lines)

    # show significance vs middle bin edge location
    binning = [min_score, max_score]
    for nbins in xrange(3): # up to 3 bins
        # linear scan
        edges, sigs, best_edge, best_sig = get_best_edge(scores, binning)
        ax1.plot(edges, sigs, color='black', linestyle=next(linecycler))
        # golden section search (doesn't work well in general)
        #best_edge, best_sig = search(optimize_func, binning[0], binning[1],
        #    scores=scores, binning=binning)
        binning.insert(1, best_edge)
        ax1.plot((best_edge, best_edge), (0, abs(best_sig)),
            color='black', linestyle='-', linewidth=2)

    #handles1, labels1 = ax1.get_legend_handles_labels()
    #handles2, labels2 = ax2.get_legend_handles_labels()
    #handles3, labels3 = ax3.get_legend_handles_labels()
    #ax2.legend(handles1+handles2+handles3, labels1+labels2+labels3)
    plt.tight_layout()

    fig.savefig('binning_{0}_{1}.png'.format(category.name, args.year % 1000))
        
    print binning

    # save the binning
    with open(os.path.join(CACHE_DIR,
                           'binning_{0}_{1}.pickle'.format(
                               category.name, args.year % 1000)), 'w') as f:
        pickle.dump(binning, f)
